{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "  \n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_x, train_y = load_mnist('./', kind='train')\n",
    "test_x, test_y = load_mnist('./', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape :  (60000, 784)\n",
      "training label shape :  (60000,)\n",
      "test set shape :  (10000, 784)\n",
      "test label shape :  (10000,)\n",
      "Number of training examples: m_train = 60000\n",
      "Number of testing examples: m_test = 10000\n",
      "Height/Width of each image: num_px = 784\n"
     ]
    }
   ],
   "source": [
    "m_train = train_x.shape[0]\n",
    "m_test = test_x.shape[0]\n",
    "num_px = train_x.shape[1]\n",
    "\n",
    "print(\"training set shape : \",train_x.shape)\n",
    "print(\"training label shape : \", train_y.shape)\n",
    "#print(\"training class shape : \", cls_train.shape)\n",
    "print(\"test set shape : \", test_x.shape)\n",
    "#print(\"test class shape : \", cls_test.shape)\n",
    "print(\"test label shape : \", test_y.shape)\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "#print (\"Each image is of size: (\" + str(np.sqrt(num_px)) + \", \" + str(np.sqrt(num_px)) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_name=['Top','Trouser','Pull over','Dress','Coat','Sandal','Skirt','Sneaker','Bag','Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth)\n",
    "    C = tf.constant(C,name=\"C\")\n",
    "    \n",
    "    # Use tf.one_hot\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    \n",
    "    # Create the session \n",
    "    sess = tf.Session()\n",
    "    \n",
    "\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "   \n",
    "    sess.close\n",
    "    \n",
    "    \n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels shape : (10, 60000)\n",
      "train example shape : (784, 60000)\n",
      "test labels shape : (10, 10000)\n",
      "test labels shape : (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "#labels = np.array([1,2,3,0,2,1])\n",
    "y_train = one_hot_matrix(train_y, C = 10)\n",
    "X_train = train_x/255.\n",
    "\n",
    "y_test = one_hot_matrix(test_y,C = 10)\n",
    "X_test = test_x/255.\n",
    "\n",
    "X_train=X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "print(\"train labels shape : \" + str(y_train.shape))\n",
    "print(\"train example shape : \" + str(X_train.shape))\n",
    "\n",
    "print(\"test labels shape : \" + str(y_test.shape))\n",
    "print(\"test labels shape : \" + str(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Our model**\n",
    "\n",
    "linear+Relu -> linear + relu ->linear+relu ->linear-> softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "  \n",
    "    X = tf.placeholder(tf.float32,shape=[n_x,None],name=\"x\")\n",
    "    Y =tf.placeholder(tf.float32,shape=[n_y,None],name=\"y\")\n",
    "\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def initialize_parameters():\n",
    "\n",
    "    \n",
    "    tf.set_random_seed(1)                  \n",
    "        \n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [80,784], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [80,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [40,80], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [40,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [20,40], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [20,1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [10,20], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [10,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "    \n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR ->RELU ->LINEAR ->RELU ->LINEAR ->RELU ->LINEAR ->SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\" , \"W4\" , \"b4\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z4 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "                                                                     \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                  \n",
    "    A1 = tf.nn.relu(Z1)                                              \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                 \n",
    "    A2 = tf.nn.relu(Z2)                                              \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 \n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 128, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    .\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 128, print_cost = True):\n",
    "\n",
    "\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "\n",
    "    cost = compute_cost(Z4, Y)\n",
    " \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "        \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "         \n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.159829\n",
      "Cost after epoch 100: 0.211038\n",
      "Cost after epoch 200: 0.143271\n",
      "Cost after epoch 300: 0.097805\n",
      "Cost after epoch 400: 0.066415\n",
      "Cost after epoch 500: 0.044593\n",
      "Cost after epoch 600: 0.027370\n",
      "Cost after epoch 700: 0.020229\n",
      "Cost after epoch 800: 0.013863\n",
      "Cost after epoch 900: 0.007730\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb52e8d0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.999817\n",
      "Test Accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**OUTPUT**\n",
    "\n",
    "<b>TEST 1 : </b> \n",
    "\n",
    "<p>Took me around 50 mins to train 1000 epochs on CPU based tensorflow</p>\n",
    "<ul>\n",
    "<li>architecture:<u> linear->relu->linear->relu->linear->relu->linear->sigmoid</u></li>\n",
    "<li>Train Accuracy : 0.999817</li>\n",
    "<li>Test Accuracy : 0.8702</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4'] \n",
    "    \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)\n",
    "    \n",
    "    return Z4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    W4 = tf.convert_to_tensor(parameters[\"W4\"])\n",
    "    b4 = tf.convert_to_tensor(parameters[\"b4\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3,\n",
    "              \"W4\": W4,\n",
    "              \"b4\": b4}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [784, 1])\n",
    "    \n",
    "    z4 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z4)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
